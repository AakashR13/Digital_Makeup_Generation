{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Recog Library Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Guide:\n",
    "https://github.com/ageitgey/face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = face_recognition.load_image_file(\"Facial_Recog_test/testface.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 1 face(s) in this photograph.\n",
      "The chin in this face has the following points: [(36, 63), (37, 97), (40, 132), (47, 164), (60, 192), (79, 217), (99, 239), (120, 258), (147, 263), (174, 258), (196, 239), (216, 216), (235, 193), (248, 166), (256, 136), (261, 104), (264, 71)]\n",
      "Number of Landmarks: 17\n",
      "The left_eyebrow in this face has the following points: [(55, 60), (73, 49), (96, 50), (118, 55), (139, 64)]\n",
      "Number of Landmarks: 5\n",
      "The right_eyebrow in this face has the following points: [(173, 64), (194, 58), (216, 54), (237, 56), (251, 69)]\n",
      "Number of Landmarks: 5\n",
      "The nose_bridge in this face has the following points: [(155, 92), (155, 111), (154, 130), (154, 150)]\n",
      "Number of Landmarks: 4\n",
      "The nose_tip in this face has the following points: [(124, 160), (138, 163), (152, 167), (166, 164), (179, 162)]\n",
      "Number of Landmarks: 5\n",
      "The left_eye in this face has the following points: [(78, 87), (93, 80), (110, 82), (123, 96), (108, 99), (90, 97)]\n",
      "Number of Landmarks: 6\n",
      "The right_eye in this face has the following points: [(184, 99), (198, 86), (215, 86), (229, 93), (216, 102), (199, 103)]\n",
      "Number of Landmarks: 6\n",
      "The top_lip in this face has the following points: [(93, 184), (115, 184), (138, 184), (151, 187), (164, 185), (184, 186), (205, 186), (197, 188), (164, 197), (151, 198), (137, 196), (100, 186)]\n",
      "Number of Landmarks: 12\n",
      "The bottom_lip in this face has the following points: [(205, 186), (183, 209), (163, 219), (149, 221), (134, 219), (113, 207), (93, 184), (100, 186), (136, 202), (150, 204), (163, 203), (197, 188)]\n",
      "Number of Landmarks: 12\n"
     ]
    }
   ],
   "source": [
    "# Find all facial features in all the faces in the image\n",
    "face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "\n",
    "print(\"I found {} face(s) in this photograph.\".format(len(face_landmarks_list)))\n",
    "\n",
    "# Create a PIL imagedraw object so we can draw on the picture\n",
    "pil_image = Image.fromarray(image)\n",
    "d = ImageDraw.Draw(pil_image)\n",
    "\n",
    "for face_landmarks in face_landmarks_list:\n",
    "\n",
    "    # Print the location of each facial feature in this image\n",
    "    for facial_feature in face_landmarks.keys():\n",
    "        print(\"The {} in this face has the following points: {}\".format(facial_feature, face_landmarks[facial_feature]))\n",
    "        print(\"Number of Landmarks: {}\".format(len(face_landmarks[facial_feature])))\n",
    "    # Let's trace out each facial feature in the image with a line!\n",
    "    for facial_feature in face_landmarks.keys():\n",
    "        d.line(face_landmarks[facial_feature], width=5) \n",
    "\n",
    "# Show the picture\n",
    "pil_image.show()\n",
    "pil_image.save('Facial_Recog_test/testface_landmarks.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otsu's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_otsu_criteria(im, th):\n",
    "    \"\"\"Otsu's method to compute criteria.\"\"\"\n",
    "    # create the thresholded image\n",
    "    thresholded_im = np.zeros(im.shape)\n",
    "    thresholded_im[im >= th] = 1\n",
    "\n",
    "    # compute weights\n",
    "    nb_pixels = im.size\n",
    "    nb_pixels1 = np.count_nonzero(thresholded_im)\n",
    "    weight1 = nb_pixels1 / nb_pixels\n",
    "    weight0 = 1 - weight1\n",
    "\n",
    "    # if one of the classes is empty, eg all pixels are below or above the threshold, that threshold will not be considered\n",
    "    # in the search for the best threshold\n",
    "    if weight1 == 0 or weight0 == 0:\n",
    "        return np.inf\n",
    "\n",
    "    # find all pixels belonging to each class\n",
    "    val_pixels1 = im[thresholded_im == 1]\n",
    "    val_pixels0 = im[thresholded_im == 0]\n",
    "\n",
    "    # compute variance of these classes\n",
    "    var1 = np.var(val_pixels1) if len(val_pixels1) > 0 else 0\n",
    "    var0 = np.var(val_pixels0) if len(val_pixels0) > 0 else 0\n",
    "\n",
    "    return weight0 * var0 + weight1 * var1\n",
    "\n",
    "im = # load your image as a numpy array.\n",
    "# For testing purposes, one can use for example im = np.random.randint(0,255, size = (50,50))\n",
    "\n",
    "# testing all thresholds from 0 to the maximum of the image\n",
    "threshold_range = range(np.max(im)+1)\n",
    "criterias = [compute_otsu_criteria(im, th) for th in threshold_range]\n",
    "\n",
    "# best threshold is the one minimizing the Otsu criteria\n",
    "best_threshold = threshold_range[np.argmin(criterias)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
